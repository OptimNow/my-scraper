# Guide de Logging StructurÃ©

## ðŸ“Š Vue d'Ensemble

Le scraper utilise maintenant un **logging structurÃ© au format JSON** pour faciliter le monitoring, le debugging et l'analyse des donnÃ©es.

---

## ðŸŽ¯ Avantages du Logging StructurÃ©

### Avant (Console.log classique)
```
Calling scraper API: http://...
Uploaded to s3://bucket/key
Scraper error: TypeError: Cannot read property...
```

**ProblÃ¨mes:**
- âŒ Difficile Ã  parser automatiquement
- âŒ Pas de timestamp prÃ©cis
- âŒ Pas de contexte (requestId, duration, etc.)
- âŒ Difficile Ã  filtrer ou analyser

### AprÃ¨s (JSON structurÃ©)
```json
{"level":"info","timestamp":"2025-02-04T10:30:00.123Z","message":"Calling scraper API","url":"http://...","limit":5}
{"level":"info","timestamp":"2025-02-04T10:30:03.456Z","message":"File uploaded to S3","bucket":"my-bucket","key":"Recos/xxx","size":1234}
{"level":"error","timestamp":"2025-02-04T10:30:05.789Z","message":"Scraper error","error":{"message":"Cannot read property...","stack":"...","name":"TypeError"}}
```

**Avantages:**
- âœ… Facile Ã  parser (JSON standard)
- âœ… Timestamps ISO 8601 prÃ©cis
- âœ… MÃ©tadonnÃ©es riches (requestId, duration, counts)
- âœ… Facile Ã  filtrer avec jq, grep, ou outils d'analyse

---

## ðŸ“ Format des Logs

Tous les logs suivent ce format de base:

```json
{
  "level": "info|warn|error",
  "timestamp": "ISO 8601 datetime",
  "message": "Human readable message",
  ...metadata
}
```

### Niveaux de Log

| Niveau | Usage | Exemple |
|--------|-------|---------|
| `info` | OpÃ©rations normales | "Scraping URL", "File uploaded" |
| `warn` | Situations inhabituelles mais non bloquantes | "Data validation warnings", "Some files failed" |
| `error` | Erreurs nÃ©cessitant attention | "Fetch timeout", "Upload failed" |

---

## ðŸ” Exemples de Logs par OpÃ©ration

### 1. RequÃªte API Scraper

**DÃ©marrage:**
```json
{
  "level": "info",
  "timestamp": "2025-02-04T10:30:00.123Z",
  "message": "Scraper request started",
  "requestId": "a7c3f2",
  "urlParam": null,
  "limit": 5,
  "singleUrl": false
}
```

**Fetch d'une page:**
```json
{
  "level": "info",
  "timestamp": "2025-02-04T10:30:01.456Z",
  "message": "Fetching document",
  "url": "https://hub.pointfive.co/hub/inefficiencies/..."
}
```

**SuccÃ¨s:**
```json
{
  "level": "info",
  "timestamp": "2025-02-04T10:30:02.789Z",
  "message": "Document fetched successfully",
  "url": "https://...",
  "size": 45678
}
```

**Validation warning:**
```json
{
  "level": "warn",
  "timestamp": "2025-02-04T10:30:03.012Z",
  "message": "Data validation warnings",
  "requestId": "a7c3f2",
  "url": "https://...",
  "errors": ["Missing or invalid title"]
}
```

**Completion:**
```json
{
  "level": "info",
  "timestamp": "2025-02-04T10:30:05.345Z",
  "message": "Scraping batch completed",
  "requestId": "a7c3f2",
  "total": 5,
  "successful": 5,
  "failed": 0,
  "duration": 5222
}
```

### 2. Erreur de Scraping

**Timeout:**
```json
{
  "level": "error",
  "timestamp": "2025-02-04T10:30:08.678Z",
  "message": "Fetch timeout",
  "error": {
    "message": "Fetch timeout after 8000ms: https://...",
    "stack": "Error: Fetch timeout...\n    at fetchDocument...",
    "name": "Error"
  },
  "url": "https://...",
  "timeout": 8000
}
```

**Erreur HTTP:**
```json
{
  "level": "error",
  "timestamp": "2025-02-04T10:30:10.901Z",
  "message": "Fetch failed",
  "error": {
    "message": "Failed to fetch https://...: HTTP 503 Service Unavailable",
    "stack": "Error: Failed to fetch...",
    "name": "Error"
  },
  "url": "https://..."
}
```

### 3. Script Batch

**Initialisation:**
```json
{
  "level": "info",
  "timestamp": "2025-02-04T11:00:00.000Z",
  "message": "Batch script initialized",
  "bucket": "my-bucket",
  "prefix": "Recos/",
  "region": "eu-central-1",
  "scraperUrl": "http://localhost:3000/api/scrape_hub"
}
```

**Appel API:**
```json
{
  "level": "info",
  "timestamp": "2025-02-04T11:00:01.234Z",
  "message": "Calling scraper API",
  "url": "http://localhost:3000/api/scrape_hub?limit=5",
  "limit": 5
}
```

**RÃ©ponse API:**
```json
{
  "level": "info",
  "timestamp": "2025-02-04T11:00:05.678Z",
  "message": "Scraper API response received",
  "itemCount": 5,
  "totalUrls": 5,
  "failed": 0,
  "requestId": "a7c3f2"
}
```

**Upload S3:**
```json
{
  "level": "info",
  "timestamp": "2025-02-04T11:00:06.789Z",
  "message": "File uploaded to S3",
  "bucket": "my-bucket",
  "key": "Recos/pointfive_hub_summary_2025-02-04T11-00-00-000Z.json",
  "size": 12345
}
```

**Completion:**
```json
{
  "level": "info",
  "timestamp": "2025-02-04T11:00:15.012Z",
  "message": "Batch upload completed",
  "totalItems": 5,
  "uploaded": 6,
  "failed": 0,
  "duration": 15012,
  "bucket": "my-bucket",
  "prefix": "Recos/"
}
```

---

## ðŸ› ï¸ Utilisation des Logs

### Filtrage avec grep

**Voir uniquement les erreurs:**
```bash
vercel logs | grep '"level":"error"'
```

**Voir un requestId spÃ©cifique:**
```bash
vercel logs | grep '"requestId":"a7c3f2"'
```

**Voir les timeouts:**
```bash
vercel logs | grep 'timeout'
```

### Parsing avec jq

**Extraire tous les messages d'erreur:**
```bash
vercel logs | jq 'select(.level == "error") | .message'
```

**Compter les succÃ¨s vs Ã©checs:**
```bash
vercel logs | jq 'select(.message == "Scraping batch completed") | {successful, failed}'
```

**Voir la durÃ©e moyenne:**
```bash
vercel logs | jq 'select(.duration) | .duration' | awk '{sum+=$1; count++} END {print sum/count}'
```

**Voir tous les URLs scrapÃ©es:**
```bash
vercel logs | jq 'select(.message == "URL scraped successfully") | .url'
```

### Analyse avec Node.js

**Script d'analyse simple:**
```javascript
const fs = require('fs');
const logs = fs.readFileSync('logs.json', 'utf8')
  .split('\n')
  .filter(line => line.trim())
  .map(line => JSON.parse(line));

// Statistiques
const errors = logs.filter(l => l.level === 'error').length;
const warnings = logs.filter(l => l.level === 'warn').length;
const successes = logs.filter(l => l.message === 'URL scraped successfully').length;

console.log({ errors, warnings, successes });

// DurÃ©e moyenne
const durations = logs
  .filter(l => l.duration)
  .map(l => l.duration);
const avgDuration = durations.reduce((a, b) => a + b, 0) / durations.length;

console.log({ avgDuration });
```

### Monitoring avec outils tiers

**DataDog, New Relic, Splunk:**
```javascript
// Les logs JSON structurÃ©s sont automatiquement parsÃ©s
// Vous pouvez crÃ©er des dashboards et alertes basÃ©s sur:
// - error.message contient "timeout"
// - duration > 5000
// - failed > 0
```

---

## ðŸ”§ Personnalisation

### Ajouter des champs custom

Si vous voulez ajouter des informations supplÃ©mentaires:

```javascript
logger.info('Custom operation', {
  customField1: 'value1',
  customField2: 42,
  customField3: { nested: 'object' }
});
```

RÃ©sultat:
```json
{
  "level": "info",
  "timestamp": "...",
  "message": "Custom operation",
  "customField1": "value1",
  "customField2": 42,
  "customField3": {"nested": "object"}
}
```

### Changer le format

Pour passer Ã  un format diffÃ©rent (ex: logfmt):

```javascript
const logger = {
  info: (msg, meta = {}) => {
    const parts = [`level=info`, `msg="${msg}"`];
    for (const [k, v] of Object.entries(meta)) {
      parts.push(`${k}="${v}"`);
    }
    console.log(parts.join(' '));
  }
};
```

---

## ðŸ“Š MÃ©triques Importantes Ã  Surveiller

### Performance
- `duration` - Temps total de l'opÃ©ration (ms)
- `size` - Taille des fichiers (bytes)
- `timeout` - Timeouts observÃ©s

### FiabilitÃ©
- `successful` / `failed` - Ratio de succÃ¨s
- `error.message` - Types d'erreurs frÃ©quents
- `validation.errors` - QualitÃ© des donnÃ©es

### Utilisation
- `requestId` - Volume de requÃªtes
- `limit` - ParamÃ¨tres utilisÃ©s
- `itemCount` - DonnÃ©es produites

---

## ðŸš¨ Alertes RecommandÃ©es

### Erreurs critiques
```javascript
if (log.level === 'error' && log.message.includes('S3')) {
  // Alert: S3 upload failures
}

if (log.level === 'error' && log.message.includes('timeout')) {
  // Alert: High number of timeouts
}
```

### DÃ©gradation de performance
```javascript
if (log.duration && log.duration > 8000) {
  // Alert: Slow operations
}

if (log.failed && log.failed > log.successful * 0.2) {
  // Alert: High failure rate (>20%)
}
```

---

## ðŸ“š Ressources

- [JSON Lines format](http://jsonlines.org/)
- [jq manual](https://stedolan.github.io/jq/manual/)
- [Structured Logging Best Practices](https://www.loggly.com/blog/structured-logging-best-practices/)
- [Vercel Logging](https://vercel.com/docs/observability/runtime-logs)

---

**ðŸ’¡ Tip:** Activez le logging structurÃ© dans vos outils de monitoring pour profiter pleinement de ces donnÃ©es !
